{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "432ba143",
   "metadata": {},
   "source": [
    "# OpenAI tests for lambda - azure function converter\n",
    "\n",
    "## Testing Chain of Thought Prompting (CoT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4caffe1",
   "metadata": {},
   "source": [
    "### Install the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc936208",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509b1e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc97f3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5584c760",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1621606",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e6cc16f",
   "metadata": {},
   "source": [
    "### Setup\n",
    "\n",
    "Import the libraries and environment variables to gain access to the `Open API Key`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd8d1ec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://devsquad-eastus-2.openai.azure.com/\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain.prompts.example_selector import SemanticSimilarityExampleSelector\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import AzureOpenAIEmbeddings\n",
    "from langchain.prompts import FewShotChatMessagePromptTemplate, ChatPromptTemplate\n",
    "from langchain.chat_models import AzureChatOpenAI\n",
    "from langchain.chains import ConversationChain\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "\n",
    "api_key=os.environ['OPENAI_API_KEY']\n",
    "base_url=os.environ['OPENAI_BASE_URL']\n",
    "api_version=os.environ['OPENAI_API_VERSION']\n",
    "\n",
    "print(base_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3964d6",
   "metadata": {},
   "source": [
    "Let's create the llm client, we can use a chat llm from langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0af16d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = AzureChatOpenAI(\n",
    "    api_key=api_key,\n",
    "    azure_endpoint=base_url, \n",
    "    api_version=api_version,\n",
    "    model=\"gpt-4\",\n",
    "    temperature=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7716a5",
   "metadata": {},
   "source": [
    "#### Create embeddings of your documents to get ready for semantic search\n",
    "\n",
    "We are going to get our embeddings engine ready. This will be the engine that will turn out documents into vector embeddings so we can easily do semantic search on them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9c13770",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = AzureOpenAIEmbeddings(\n",
    "    api_key=api_key,\n",
    "    azure_endpoint=base_url, \n",
    "    api_version=api_version,\n",
    "    azure_deployment=\"text-embedding-ada-002\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b954ee49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.012222584727053142, 0.007210398239221619, -0.014818063280923785]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"this is a test document\"\n",
    "query_result = embeddings.embed_query(text)\n",
    "doc_result = embeddings.embed_documents([text])\n",
    "doc_result[0][:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbee06e5",
   "metadata": {},
   "source": [
    "### Create the example set\n",
    "To get started, create a list of few-shot examples. Each example should be a dictionary with the keys being the input variables and the values being the values for those input variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c74592",
   "metadata": {},
   "source": [
    "**Note:** An improvement could be to add metadata to the examples to help recognize the most similar ones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a71c131",
   "metadata": {},
   "source": [
    "Let's start by getting a list of paths with the examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f10c8f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_files_in_folders(path):\n",
    "    return os.listdir(path)\n",
    "\n",
    "def read_file(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        content = file.read()\n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7dfc802",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['basic-conversion-1', 'basic-conversion-2', 'basic-conversion-3', 'basic-conversion-4', 'basic-conversion-5', 's3-conversion-1']\n"
     ]
    }
   ],
   "source": [
    "basePath = \"../go-examplesexamples/gin/\"\n",
    "pathList = list_files_in_folders(basePath)\n",
    "print(pathList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce7c11e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = []\n",
    "\n",
    "for path in pathList:\n",
    "    input = read_file(basePath + path + \"/input/main.go\")\n",
    "    output = read_file(basePath + path + \"/output/main.go\")\n",
    "    exampleName = path\n",
    "    example = {\n",
    "        \"input\": input, \n",
    "        \"output\": output,\n",
    "        # \"metadata\": {\"name\": exampleName, \"language\": \"go\"}\n",
    "    }\n",
    "    examples.append(example)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26557a88",
   "metadata": {},
   "source": [
    "Checkout one example and see if it's good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea2139d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input': 'package main\\n\\nimport (\\n\\t\"context\"\\n\\t\"fmt\"\\n\\n\\t\"github.com/aws/aws-lambda-go/lambda\"\\n)\\n\\ntype MyEvent struct {\\n\\tName string `json:\"name\"`\\n}\\n\\ntype MyResponse struct {\\n\\tMessage string `json:\"message\"`\\n}\\n\\nfunc HandleRequest(ctx context.Context, event *MyEvent) (*MyResponse, error) {\\n\\tif event == nil {\\n\\t\\treturn nil, fmt.Errorf(\"received nil event\")\\n\\t}\\n\\tmessage := fmt.Sprintf(\"Hello %s!\", event.Name)\\n\\treturn &MyResponse{Message: message}, nil\\n}\\n\\nfunc main() {\\n\\tlambda.Start(HandleRequest)\\n}\\n', 'output': 'package main\\n\\nimport (\\n\\t\"fmt\"\\n\\t\"log\"\\n\\t\"net/http\"\\n\\t\"os\"\\n\\n\\t\"github.com/gin-gonic/gin\"\\n)\\n\\nconst (\\n\\tEnvVarAzureFunctionPort = \"FUNCTIONS_PORT\"\\n)\\n\\ntype MyEvent struct {\\n\\tName string `json:\"name\"`\\n}\\n\\ntype MyResponse struct {\\n\\tMessage string `json:\"message\"`\\n}\\n\\nfunc HandleRequest(ctx *gin.Context)  {\\n\\tif ctx.Request.Body == nil {\\n\\t\\terrorMsg := \"received nil event\"\\n\\t\\tctx.JSON(http.StatusBadRequest, gin.H{\"error\": errorMsg})\\n\\t\\treturn \\n\\t}\\n\\n\\tvar event MyEvent\\n\\terr := ctx.Bind(&event)\\n\\tif err != nil {\\n\\t\\terrorMsg := fmt.Sprintf(\"error on reading request body: %v\\\\n\", err.Error())\\n\\t\\tctx.JSON(http.StatusBadRequest, gin.H{\"error\": errorMsg})\\n\\t\\treturn\\n\\t}\\n\\n\\tmessage := fmt.Sprintf(\"Hello %s!\", event.Name)\\n\\tctx.JSON(http.StatusOK, &MyResponse{Message: message})\\n}\\n\\nfunc main() {\\n\\tr := gin.Default()\\n\\tr.Handle(http.MethodPost, \"/HandleRequest\", HandleRequest)\\n\\n\\tport := os.Getenv(EnvVarAzureFunctionPort)\\n\\tif port == \"\" {\\n\\t\\tport = \"8080\"\\n\\t}\\n\\thost := fmt.Sprintf(\"0.0.0.0:%s\", port)\\n\\tfmt.Printf(\"Go server Listening...on port: %s\\\\n\", port)\\n\\tlog.Fatal(r.Run(host))\\n}\\n'}\n"
     ]
    }
   ],
   "source": [
    "print(examples[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "305348e4",
   "metadata": {},
   "source": [
    "### Test input\n",
    "\n",
    "Let's define the target input that we'll use to select the examples and finally to run our query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f7db03dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = read_file(\"../go-examplesexamples/test-inputs/basic-input-1/main.go\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc12f7b",
   "metadata": {},
   "source": [
    "### Using Advanced Chain-of-Thought (CoT) Prompt\n",
    "\n",
    "Add a system input that explains the steps the LLM needs to follow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "71a93ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_input = '''\n",
    "You are an AI assistant that translates go lambda functions to azure functions, \n",
    "\n",
    "You follow the next steps:\n",
    "Step 1. when ever you encounter this code:\n",
    "\n",
    "func main() {{\n",
    "\tlambda.Start(HandleRequest)\n",
    "}}\n",
    "\n",
    "You replace it with a gin server like this:\n",
    "\n",
    "func azureHandler(ctx *gin.Context)  {{\n",
    "\tvar event MyEvent\n",
    "\terr := ctx.Bind(&event)\n",
    "\tif err != nil {{\n",
    "\t\terrorMsg := fmt.Sprintf(\"error on reading request body: %v\\n\", err.Error())\n",
    "\t\tctx.JSON(http.StatusBadRequest, gin.H{{\"error\": errorMsg}})\n",
    "\t\treturn\n",
    "\t}}\n",
    "\n",
    "\tmessage := fmt.Sprintf(\"Hello %s!\", event.Name)\n",
    "\tctx.JSON(http.StatusOK, &MyResponse{{Message: message}})\n",
    "}}\n",
    "\n",
    "func main() {{\n",
    "\tr := gin.Default()\n",
    "\tr.Handle(http.MethodPost, \"/HandleRequest\", azureHandler)\n",
    "\n",
    "\tport := os.Getenv(EnvVarAzureFunctionPort)\n",
    "\tif port == \"\" {{\n",
    "\t\tport = \"8080\"\n",
    "\t}}\n",
    "\thost := fmt.Sprintf(\"0.0.0.0:%s\", port)\n",
    "\tfmt.Printf(\"Go server Listening...on port: %s\\n\", port)\n",
    "\tlog.Fatal(r.Run(host))\n",
    "}}\n",
    "\n",
    "You always return only GO code you never return ENGLISH. Any explanations you require will be comments in code.\n",
    "If you don't know the answer return the original code with the following comment\n",
    "\n",
    "// No code could be converted, please check the class\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790f0b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(system_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d55cb5e",
   "metadata": {},
   "source": [
    "### Using an example selector\n",
    "\n",
    "We will reuse the example set and the formatter from the previous section. However, instead of feeding the examples directly into the `FewShotPromptTemplate` object, we will feed them into an `ExampleSelector` object.\n",
    "\n",
    "In this tutorial, we will use the `SemanticSimilarityExampleSelector` class. This class selects few-shot examples based on their similarity to the input. It uses an embedding model to compute the similarity between the input and the few-shot examples, as well as a vector store to perform the nearest neighbor search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9ec774f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# metadatas = [example[\"metadata\"] for example in examples]\n",
    "to_vectorize = [\" \".join(example.values()) for example in examples]\n",
    "vectorstore = Chroma.from_texts(to_vectorize, embeddings, metadatas=examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "105eb45c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'input': 'package main\\n\\nimport (\\n\\t\"context\"\\n\\t\"fmt\"\\n\\n\\t\"github.com/aws/aws-lambda-go/lambda\"\\n)\\n\\ntype MyEvent struct {\\n\\tName string `json:\"name\"`\\n}\\n\\ntype MyResponse struct {\\n\\tMessage string `json:\"message\"`\\n}\\n\\nfunc HandleRequest(ctx context.Context, event *MyEvent) (*MyResponse, error) {\\n\\tif event == nil {\\n\\t\\treturn nil, fmt.Errorf(\"received nil event\")\\n\\t}\\n\\tmessage := fmt.Sprintf(\"Hello %s!\", event.Name)\\n\\treturn &MyResponse{Message: message}, nil\\n}\\n\\nfunc main() {\\n\\tlambda.Start(HandleRequest)\\n}\\n',\n",
       "  'output': 'package main\\n\\nimport (\\n\\t\"fmt\"\\n\\t\"log\"\\n\\t\"net/http\"\\n\\t\"os\"\\n\\n\\t\"github.com/gin-gonic/gin\"\\n)\\n\\nconst (\\n\\tEnvVarAzureFunctionPort = \"FUNCTIONS_PORT\"\\n)\\n\\ntype MyEvent struct {\\n\\tName string `json:\"name\"`\\n}\\n\\ntype MyResponse struct {\\n\\tMessage string `json:\"message\"`\\n}\\n\\nfunc HandleRequest(ctx *gin.Context)  {\\n\\tif ctx.Request.Body == nil {\\n\\t\\terrorMsg := \"received nil event\"\\n\\t\\tctx.JSON(http.StatusBadRequest, gin.H{\"error\": errorMsg})\\n\\t\\treturn \\n\\t}\\n\\n\\tvar event MyEvent\\n\\terr := ctx.Bind(&event)\\n\\tif err != nil {\\n\\t\\terrorMsg := fmt.Sprintf(\"error on reading request body: %v\\\\n\", err.Error())\\n\\t\\tctx.JSON(http.StatusBadRequest, gin.H{\"error\": errorMsg})\\n\\t\\treturn\\n\\t}\\n\\n\\tmessage := fmt.Sprintf(\"Hello %s!\", event.Name)\\n\\tctx.JSON(http.StatusOK, &MyResponse{Message: message})\\n}\\n\\nfunc main() {\\n\\tr := gin.Default()\\n\\tr.Handle(http.MethodPost, \"/HandleRequest\", HandleRequest)\\n\\n\\tport := os.Getenv(EnvVarAzureFunctionPort)\\n\\tif port == \"\" {\\n\\t\\tport = \"8080\"\\n\\t}\\n\\thost := fmt.Sprintf(\"0.0.0.0:%s\", port)\\n\\tfmt.Printf(\"Go server Listening...on port: %s\\\\n\", port)\\n\\tlog.Fatal(r.Run(host))\\n}\\n'}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_selector = SemanticSimilarityExampleSelector(\n",
    "    vectorstore=vectorstore,\n",
    "    k=1,\n",
    ")\n",
    "\n",
    "# The prompt template will load examples by passing the input do the `select_examples` method\n",
    "example_selector.select_examples({\"input\": input})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c5d78d",
   "metadata": {},
   "source": [
    "### Create a formatter for the few-shot examples\n",
    "Configure a formatter that will format the few-shot examples into a string. This formatter should be a `FewShotChatMessagePromptTemplate` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8b1656af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the few-shot prompt.\n",
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    # The input variables select the values to pass to the example_selector\n",
    "    input_variables=[\"input\"],\n",
    "    example_selector=example_selector,\n",
    "    # Define how each example will be formatted.\n",
    "    # In this case, each example will become 2 messages:\n",
    "    # 1 human, and 1 AI\n",
    "    example_prompt=ChatPromptTemplate.from_messages(\n",
    "        [(\"human\", \"{input}\"), (\"ai\", \"{output}\")]\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f04a294d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: package main\n",
      "\n",
      "import (\n",
      "\t\"context\"\n",
      "\t\"fmt\"\n",
      "\n",
      "\t\"github.com/aws/aws-lambda-go/lambda\"\n",
      ")\n",
      "\n",
      "type MyEvent struct {\n",
      "\tName string `json:\"name\"`\n",
      "}\n",
      "\n",
      "type MyResponse struct {\n",
      "\tMessage string `json:\"message\"`\n",
      "}\n",
      "\n",
      "func HandleRequest(ctx context.Context, event *MyEvent) (*MyResponse, error) {\n",
      "\tif event == nil {\n",
      "\t\treturn nil, fmt.Errorf(\"received nil event\")\n",
      "\t}\n",
      "\tmessage := fmt.Sprintf(\"Hello %s!\", event.Name)\n",
      "\treturn &MyResponse{Message: message}, nil\n",
      "}\n",
      "\n",
      "func main() {\n",
      "\tlambda.Start(HandleRequest)\n",
      "}\n",
      "\n",
      "AI: package main\n",
      "\n",
      "import (\n",
      "\t\"fmt\"\n",
      "\t\"log\"\n",
      "\t\"net/http\"\n",
      "\t\"os\"\n",
      "\n",
      "\t\"github.com/gin-gonic/gin\"\n",
      ")\n",
      "\n",
      "const (\n",
      "\tEnvVarAzureFunctionPort = \"FUNCTIONS_PORT\"\n",
      ")\n",
      "\n",
      "type MyEvent struct {\n",
      "\tName string `json:\"name\"`\n",
      "}\n",
      "\n",
      "type MyResponse struct {\n",
      "\tMessage string `json:\"message\"`\n",
      "}\n",
      "\n",
      "func HandleRequest(ctx *gin.Context)  {\n",
      "\tif ctx.Request.Body == nil {\n",
      "\t\terrorMsg := \"received nil event\"\n",
      "\t\tctx.JSON(http.StatusBadRequest, gin.H{\"error\": errorMsg})\n",
      "\t\treturn \n",
      "\t}\n",
      "\n",
      "\tvar event MyEvent\n",
      "\terr := ctx.Bind(&event)\n",
      "\tif err != nil {\n",
      "\t\terrorMsg := fmt.Sprintf(\"error on reading request body: %v\\n\", err.Error())\n",
      "\t\tctx.JSON(http.StatusBadRequest, gin.H{\"error\": errorMsg})\n",
      "\t\treturn\n",
      "\t}\n",
      "\n",
      "\tmessage := fmt.Sprintf(\"Hello %s!\", event.Name)\n",
      "\tctx.JSON(http.StatusOK, &MyResponse{Message: message})\n",
      "}\n",
      "\n",
      "func main() {\n",
      "\tr := gin.Default()\n",
      "\tr.Handle(http.MethodPost, \"/HandleRequest\", HandleRequest)\n",
      "\n",
      "\tport := os.Getenv(EnvVarAzureFunctionPort)\n",
      "\tif port == \"\" {\n",
      "\t\tport = \"8080\"\n",
      "\t}\n",
      "\thost := fmt.Sprintf(\"0.0.0.0:%s\", port)\n",
      "\tfmt.Printf(\"Go server Listening...on port: %s\\n\", port)\n",
      "\tlog.Fatal(r.Run(host))\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(few_shot_prompt.format(input=input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bcc77401",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_input),\n",
    "        few_shot_prompt,\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6d1fc79a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System: \n",
      "You are an AI assistant that translates go lambda functions to azure functions, \n",
      "\n",
      "You follow the next steps:\n",
      "Step 1. when ever you encounter this code:\n",
      "\n",
      "func main() {\n",
      "\tlambda.Start(HandleRequest)\n",
      "}\n",
      "\n",
      "You replace it with a gin server like this:\n",
      "\n",
      "func azureHandler(ctx *gin.Context)  {\n",
      "\tvar event MyEvent\n",
      "\terr := ctx.Bind(&event)\n",
      "\tif err != nil {\n",
      "\t\terrorMsg := fmt.Sprintf(\"error on reading request body: %v\n",
      "\", err.Error())\n",
      "\t\tctx.JSON(http.StatusBadRequest, gin.H{\"error\": errorMsg})\n",
      "\t\treturn\n",
      "\t}\n",
      "\n",
      "\tmessage := fmt.Sprintf(\"Hello %s!\", event.Name)\n",
      "\tctx.JSON(http.StatusOK, &MyResponse{Message: message})\n",
      "}\n",
      "\n",
      "func main() {\n",
      "\tr := gin.Default()\n",
      "\tr.Handle(http.MethodPost, \"/HandleRequest\", azureHandler)\n",
      "\n",
      "\tport := os.Getenv(EnvVarAzureFunctionPort)\n",
      "\tif port == \"\" {\n",
      "\t\tport = \"8080\"\n",
      "\t}\n",
      "\thost := fmt.Sprintf(\"0.0.0.0:%s\", port)\n",
      "\tfmt.Printf(\"Go server Listening...on port: %s\n",
      "\", port)\n",
      "\tlog.Fatal(r.Run(host))\n",
      "}\n",
      "\n",
      "You always return only GO code you never return ENGLISH. Any explanations you require will be comments in code.\n",
      "If you don't know the answer return the original code with the following comment\n",
      "\n",
      "// No code could be converted, please check the class\n",
      "\n",
      "Human: package main\n",
      "\n",
      "import (\n",
      "\t\"context\"\n",
      "\t\"fmt\"\n",
      "\n",
      "\t\"github.com/aws/aws-lambda-go/lambda\"\n",
      ")\n",
      "\n",
      "type MyEvent struct {\n",
      "\tName string `json:\"name\"`\n",
      "}\n",
      "\n",
      "type MyResponse struct {\n",
      "\tMessage string `json:\"message\"`\n",
      "}\n",
      "\n",
      "func HandleRequest(ctx context.Context, event *MyEvent) (*MyResponse, error) {\n",
      "\tif event == nil {\n",
      "\t\treturn nil, fmt.Errorf(\"received nil event\")\n",
      "\t}\n",
      "\tmessage := fmt.Sprintf(\"Hello %s!\", event.Name)\n",
      "\treturn &MyResponse{Message: message}, nil\n",
      "}\n",
      "\n",
      "func main() {\n",
      "\tlambda.Start(HandleRequest)\n",
      "}\n",
      "\n",
      "AI: package main\n",
      "\n",
      "import (\n",
      "\t\"fmt\"\n",
      "\t\"log\"\n",
      "\t\"net/http\"\n",
      "\t\"os\"\n",
      "\n",
      "\t\"github.com/gin-gonic/gin\"\n",
      ")\n",
      "\n",
      "const (\n",
      "\tEnvVarAzureFunctionPort = \"FUNCTIONS_PORT\"\n",
      ")\n",
      "\n",
      "type MyEvent struct {\n",
      "\tName string `json:\"name\"`\n",
      "}\n",
      "\n",
      "type MyResponse struct {\n",
      "\tMessage string `json:\"message\"`\n",
      "}\n",
      "\n",
      "func HandleRequest(ctx *gin.Context)  {\n",
      "\tif ctx.Request.Body == nil {\n",
      "\t\terrorMsg := \"received nil event\"\n",
      "\t\tctx.JSON(http.StatusBadRequest, gin.H{\"error\": errorMsg})\n",
      "\t\treturn \n",
      "\t}\n",
      "\n",
      "\tvar event MyEvent\n",
      "\terr := ctx.Bind(&event)\n",
      "\tif err != nil {\n",
      "\t\terrorMsg := fmt.Sprintf(\"error on reading request body: %v\\n\", err.Error())\n",
      "\t\tctx.JSON(http.StatusBadRequest, gin.H{\"error\": errorMsg})\n",
      "\t\treturn\n",
      "\t}\n",
      "\n",
      "\tmessage := fmt.Sprintf(\"Hello %s!\", event.Name)\n",
      "\tctx.JSON(http.StatusOK, &MyResponse{Message: message})\n",
      "}\n",
      "\n",
      "func main() {\n",
      "\tr := gin.Default()\n",
      "\tr.Handle(http.MethodPost, \"/HandleRequest\", HandleRequest)\n",
      "\n",
      "\tport := os.Getenv(EnvVarAzureFunctionPort)\n",
      "\tif port == \"\" {\n",
      "\t\tport = \"8080\"\n",
      "\t}\n",
      "\thost := fmt.Sprintf(\"0.0.0.0:%s\", port)\n",
      "\tfmt.Printf(\"Go server Listening...on port: %s\\n\", port)\n",
      "\tlog.Fatal(r.Run(host))\n",
      "}\n",
      "\n",
      "Human: package main\n",
      "\n",
      "import (\n",
      "\t\"context\"\n",
      "\t\"fmt\"\n",
      "\t\"github.com/aws/aws-lambda-go/lambda\"\n",
      "\t\"github.com/msft-latam-devsquad/lambda-to-azure-converter/examples/storage\"\n",
      ")\n",
      "\n",
      "type SaveRequest struct {\n",
      "\tId string `json:\"id\"`\n",
      "}\n",
      "\n",
      "type Response struct {\n",
      "\tMessage string `json:\"message\"`\n",
      "}\n",
      "\n",
      "func HandleRequest(ctx context.Context, req *SaveRequest) (*Response, error) {\n",
      "\tif req == nil {\n",
      "\t\treturn nil, fmt.Errorf(\"request can't be nil\")\n",
      "\t}\n",
      "\t\n",
      "\tazStore := storage.NewAzureStorage()\n",
      "\terr := azStore.Save(ctx, req.Id)\n",
      "\tif err != nil {\n",
      "\t\treturn nil, err\n",
      "\t}\n",
      "\n",
      "\tmessage := fmt.Sprintf(\"request %s was successfully saved\", req.Id)\n",
      "\treturn &Response{Message: message}, nil\n",
      "}\n",
      "\n",
      "func main() {\n",
      "\tlambda.Start(HandleRequest)\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(final_prompt.format(input=input))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b66abf00",
   "metadata": {},
   "source": [
    "### Use with an LLM\n",
    "Now, you can connect your model to the few-shot prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ec6fb91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation = ConversationChain(llm=llm)\n",
    "\n",
    "result = conversation.run(final_prompt.format_messages(input=input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4201fad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```go\n",
      "package main\n",
      "\n",
      "import (\n",
      "\t\"context\"\n",
      "\t\"fmt\"\n",
      "\t\"log\"\n",
      "\t\"net/http\"\n",
      "\t\"os\"\n",
      "\n",
      "\t\"github.com/gin-gonic/gin\"\n",
      "\t\"github.com/msft-latam-devsquad/lambda-to-azure-converter/examples/storage\"\n",
      ")\n",
      "\n",
      "const (\n",
      "\tEnvVarAzureFunctionPort = \"FUNCTIONS_PORT\"\n",
      ")\n",
      "\n",
      "type SaveRequest struct {\n",
      "\tId string `json:\"id\"`\n",
      "}\n",
      "\n",
      "type Response struct {\n",
      "\tMessage string `json:\"message\"`\n",
      "}\n",
      "\n",
      "// HandleRequest is converted from AWS Lambda to Azure Function using Gin\n",
      "func azureHandler(ctx *gin.Context) {\n",
      "\tif ctx.Request.Body == nil {\n",
      "\t\terrorMsg := \"request can't be nil\"\n",
      "\t\tctx.JSON(http.StatusBadRequest, gin.H{\"error\": errorMsg})\n",
      "\t\treturn\n",
      "\t}\n",
      "\n",
      "\tvar req SaveRequest\n",
      "\terr := ctx.Bind(&req)\n",
      "\tif err != nil {\n",
      "\t\terrorMsg := fmt.Sprintf(\"error on reading request body: %v\\n\", err.Error())\n",
      "\t\tctx.JSON(http.StatusBadRequest, gin.H{\"error\": errorMsg})\n",
      "\t\treturn\n",
      "\t}\n",
      "\n",
      "\tazStore := storage.NewAzureStorage()\n",
      "\terr = azStore.Save(context.Background(), req.Id)\n",
      "\tif err != nil {\n",
      "\t\tctx.JSON(http.StatusInternalServerError, gin.H{\"error\": err.Error()})\n",
      "\t\treturn\n",
      "\t}\n",
      "\n",
      "\tmessage := fmt.Sprintf(\"request %s was successfully saved\", req.Id)\n",
      "\tctx.JSON(http.StatusOK, &Response{Message: message})\n",
      "}\n",
      "\n",
      "func main() {\n",
      "\tr := gin.Default()\n",
      "\tr.Handle(http.MethodPost, \"/HandleRequest\", azureHandler)\n",
      "\n",
      "\tport := os.Getenv(EnvVarAzureFunctionPort)\n",
      "\tif port == \"\" {\n",
      "\t\tport = \"8080\"\n",
      "\t}\n",
      "\thost := fmt.Sprintf(\"0.0.0.0:%s\", port)\n",
      "\tfmt.Printf(\"Go server Listening...on port: %s\\n\", port)\n",
      "\tlog.Fatal(r.Run(host))\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97621902",
   "metadata": {},
   "source": [
    "### Check if compiles \n",
    "\n",
    "The idea would be to compile the classes and if it doesn't compile tell the LLM the issue and retry.\n",
    "\n",
    "The result doesn't seem to compile let's ask the LLM again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7522456",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation.run(\"the code doesn't compile\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efefb22c",
   "metadata": {},
   "source": [
    "### Let's try with format instructions\n",
    "\n",
    "It's possible to tell our LLM how we expect to get our response back using output parsers, let's try it out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31165df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a2f732a0",
   "metadata": {},
   "source": [
    "### Testing more inputs\n",
    "\n",
    "Try again using new inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0822d811",
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_code_1 = '''\n",
    "package main\n",
    "\n",
    "import (\n",
    "\t\"context\"\n",
    "\t\"encoding/json\"\n",
    "\t\"github.com/aws/aws-lambda-go/events\"\n",
    "\truntime \"github.com/aws/aws-lambda-go/lambda\"\n",
    "\t\"github.com/aws/aws-lambda-go/lambdacontext\"\n",
    "\t\"github.com/aws/aws-sdk-go/aws/session\"\n",
    "\t\"github.com/aws/aws-sdk-go/service/lambda\"\n",
    "\t\"log\"\n",
    "\t\"os\"\n",
    ")\n",
    "\n",
    "var client = lambda.New(session.New())\n",
    "\n",
    "func callLambda() (string, error) {\n",
    "\tinput := &lambda.GetAccountSettingsInput{}\n",
    "\treq, resp := client.GetAccountSettingsRequest(input)\n",
    "\terr := req.Send()\n",
    "\toutput, _ := json.Marshal(resp.AccountUsage)\n",
    "\treturn string(output), err\n",
    "}\n",
    "\n",
    "func handleRequest(ctx context.Context, event events.SQSEvent) (string, error) {\n",
    "\t// event\n",
    "\teventJson, _ := json.MarshalIndent(event, \"\", \"  \")\n",
    "\tlog.Printf(\"EVENT: %s\", eventJson)\n",
    "\t// environment variables\n",
    "\tlog.Printf(\"REGION: %s\", os.Getenv(\"AWS_REGION\"))\n",
    "\tlog.Println(\"ALL ENV VARS:\")\n",
    "\tfor _, element := range os.Environ() {\n",
    "\t\tlog.Println(element)\n",
    "\t}\n",
    "\t// request context\n",
    "\tlc, _ := lambdacontext.FromContext(ctx)\n",
    "\tlog.Printf(\"REQUEST ID: %s\", lc.AwsRequestID)\n",
    "\t// global variable\n",
    "\tlog.Printf(\"FUNCTION NAME: %s\", lambdacontext.FunctionName)\n",
    "\t// context method\n",
    "\tdeadline, _ := ctx.Deadline()\n",
    "\tlog.Printf(\"DEADLINE: %s\", deadline)\n",
    "\t// AWS SDK call\n",
    "\tusage, err := callLambda()\n",
    "\tif err != nil {\n",
    "\t\treturn \"ERROR\", err\n",
    "\t}\n",
    "\treturn usage, nil\n",
    "}\n",
    "\n",
    "func main() {\n",
    "\truntime.Start(handleRequest)\n",
    "}\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2187c66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation = ConversationChain(llm=llm)\n",
    "\n",
    "result = conversation.run(final_prompt.format_messages(input=lambda_code_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1315319",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
