{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "432ba143",
   "metadata": {},
   "source": [
    "# OpenAI tests for lambda - azure function converter\n",
    "\n",
    "## Testing Chain of Thought Prompting (CoT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4caffe1",
   "metadata": {},
   "source": [
    "### Install the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc936208",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509b1e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc97f3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5584c760",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1621606",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e6cc16f",
   "metadata": {},
   "source": [
    "### Setup\n",
    "\n",
    "Import the libraries and environment variables to gain access to the `Open API Key`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd8d1ec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://devsquad-eastus-2.openai.azure.com/\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain.prompts.example_selector import SemanticSimilarityExampleSelector\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import AzureOpenAIEmbeddings\n",
    "from langchain.prompts import FewShotChatMessagePromptTemplate, ChatPromptTemplate\n",
    "from langchain.chat_models import AzureChatOpenAI\n",
    "from langchain.chains import ConversationChain\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "\n",
    "api_key=os.environ['OPENAI_API_KEY']\n",
    "base_url=os.environ['OPENAI_BASE_URL']\n",
    "\n",
    "print(base_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3964d6",
   "metadata": {},
   "source": [
    "Let's create the llm client, we can use a chat llm from langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0af16d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = AzureChatOpenAI(\n",
    "    api_key=api_key,\n",
    "    azure_endpoint=base_url, \n",
    "    api_version=\"2023-07-01-preview\",\n",
    "    model=\"gpt-4\",\n",
    "    temperature=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7716a5",
   "metadata": {},
   "source": [
    "#### Create embeddings of your documents to get ready for semantic search\n",
    "\n",
    "We are going to get our embeddings engine ready. This will be the engine that will turn out documents into vector embeddings so we can easily do semantic search on them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9c13770",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = AzureOpenAIEmbeddings(\n",
    "    api_key=api_key,\n",
    "    azure_endpoint=base_url, \n",
    "    api_version=\"2023-07-01-preview\",\n",
    "    azure_deployment=\"text-embedding-ada-002\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b954ee49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.012222584727053142,\n",
       " 0.007210398239221619,\n",
       " -0.014818063280923785,\n",
       " -0.026444746872933574,\n",
       " -0.003433049970082691]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"this is a test document\"\n",
    "query_result = embeddings.embed_query(text)\n",
    "doc_result = embeddings.embed_documents([text])\n",
    "doc_result[0][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbee06e5",
   "metadata": {},
   "source": [
    "### Create the example set\n",
    "To get started, create a list of few-shot examples. Each example should be a dictionary with the keys being the input variables and the values being the values for those input variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c74592",
   "metadata": {},
   "source": [
    "**TODO:** Add metadata to examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d107913",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [\n",
    "    {\n",
    "        \"input\": '''\n",
    "package main\n",
    "\n",
    "import (\n",
    "\t\"context\"\n",
    "\t\"fmt\"\n",
    "\t\"github.com/aws/aws-lambda-go/lambda\"\n",
    ")\n",
    "\n",
    "type MyEvent struct {\n",
    "\tName string `json:\"name\"`\n",
    "}\n",
    "\n",
    "type MyResponse struct {\n",
    "\tMessage string `json:\"message\"`\n",
    "}\n",
    "\n",
    "func HandleRequest(ctx context.Context, event *MyEvent) (*MyResponse, error) {\n",
    "\tif event == nil {\n",
    "\t\treturn nil, fmt.Errorf(\"received nil event\")\n",
    "\t}\n",
    "\tmessage := fmt.Sprintf(\"Hello %s!\", event.Name)\n",
    "\treturn &MyResponse{Message: message}, nil\n",
    "}\n",
    "\n",
    "func main() {\n",
    "\tlambda.Start(HandleRequest)\n",
    "}\n",
    "\n",
    "        ''',\n",
    "        \"output\": '''\n",
    "package main\n",
    "\n",
    "import (\n",
    "\t\"fmt\"\n",
    "\t\"log\"\n",
    "\t\"net/http\"\n",
    "\t\"os\"\n",
    "\n",
    "\t\"github.com/gin-gonic/gin\"\n",
    ")\n",
    "\n",
    "const (\n",
    "\tEnvVarAzureFunctionPort string = \"FUNCTIONS_PORT\"\n",
    ")\n",
    "\n",
    "type MyEvent struct {\n",
    "\tName string `json:\"name\"`\n",
    "}\n",
    "\n",
    "type MyResponse struct {\n",
    "\tMessage string `json:\"message\"`\n",
    "}\n",
    "\n",
    "func HandleRequest(ctx *gin.Context) {\n",
    "\tif ctx.Request.Body == nil {\n",
    "        errorMsg := \"received nil event\"    \n",
    "\t\tfmt.Println(errorMsg)\n",
    "\t\tctx.JSON(http.StatusBadRequest, gin.H{\"error\": errorMsg})\n",
    "\t\treturn\n",
    "\t}\n",
    "\n",
    "\tvar event MyEvent\n",
    "\terr := ctx.Bind(&event)\n",
    "\tif err != nil {\n",
    "\t\tfmt.Printf(\"error on reading request body: %v\\n\", err.Error())\n",
    "\t\tctx.JSON(http.StatusBadRequest, gin.H{\"error\": err.Error()})\n",
    "\t\treturn\n",
    "\t}\n",
    "\tmessage := fmt.Sprintf(\"Hello %s!\", event.Name)\n",
    "    ctx.JSON(http.StatusOK, &MyResponse{Message: message})\n",
    "}\n",
    "\n",
    "\n",
    "func main() {\n",
    " r := gin.Default()\n",
    " r.Handle(http.MethodPost, \"/HandleRequest\", HandleRequest)\n",
    "\n",
    " port, _ := os.LookupEnv(EnvVarAzureFunctionPort)\n",
    " host := fmt.Sprintf(\"0.0.0.0:%s\", port)\n",
    " fmt.Println(\"Go server Listening...on port: \", port)\n",
    " log.Panic(r.Run(host))\n",
    "}\n",
    "\n",
    "        '''\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ea59e6",
   "metadata": {},
   "source": [
    "### Test input\n",
    "\n",
    "Let's define the target input that we'll use to select the examples and finally to run our query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0ab7e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = '''\n",
    "package main\n",
    "\n",
    "import (\n",
    "\t\"context\"\n",
    "\t\"fmt\"\n",
    "\t\"github.com/aws/aws-lambda-go/lambda\"\n",
    "\t\"github.com/msft-latam-devsquad/lambda-to-azure-converter/examples/storage\"\n",
    ")\n",
    "\n",
    "type SaveRequest struct {\n",
    "\tId string `json:\"id\"`\n",
    "}\n",
    "\n",
    "type Response struct {\n",
    "\tMessage string `json:\"message\"`\n",
    "}\n",
    "\n",
    "func HandleRequest(ctx context.Context, req *SaveRequest) (*Response, error) {\n",
    "\tif req == nil {\n",
    "\t\treturn nil, fmt.Errorf(\"request can't be nil\")\n",
    "\t}\n",
    "\t\n",
    "\tazStore := storage.NewAzureStorage()\n",
    "\terr := azStore.Save(ctx, req.Id)\n",
    "\tif err != nil {\n",
    "\t\treturn nil, err\n",
    "\t}\n",
    "\n",
    "\tmessage := fmt.Sprintf(\"request %s was successfully saved\", req.Id)\n",
    "\treturn &Response{Message: message}, nil\n",
    "}\n",
    "\n",
    "func main() {\n",
    "\tlambda.Start(HandleRequest)\n",
    "}   \n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc12f7b",
   "metadata": {},
   "source": [
    "### Using Advanced Chain-of-Thought (CoT) Prompt\n",
    "\n",
    "Add a system input that explains the steps the LLM needs to follow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ac90efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_input = '''\n",
    "You are an AI assistant that translates go lambda functions to azure functions, \n",
    "\n",
    "You follow the next steps:\n",
    "Step 1. when ever you encounter this code:\n",
    "\n",
    "```\n",
    "func main() {\n",
    "\tlambda.Start(HandleRequest)\n",
    "}\n",
    "```\n",
    "\n",
    "You replace it with this one:\n",
    "\n",
    "```\n",
    "func azureHandler(w http.ResponseWriter, r *http.Request) {\n",
    "    fmt.Printf(\"This HTTP triggered function executed successfully. Pass a name in the query string for a personalized response.\\n\")\n",
    "    reqData, err := io.ReadAll( r.Body )\n",
    "\tif err != nil {\n",
    "\t\tfmt.Printf(\"error on reading request body: %v\\n\", err.Error())\n",
    "\t\tw.WriteHeader(http.StatusBadRequest)\n",
    "\t\tw.Write([]byte(err.Error()))\n",
    "\t\treturn\t\n",
    "\t}\n",
    "\tvar event MyEvent\n",
    "\terr = json.Unmarshal(reqData, &event)\n",
    "\tif err != nil {\n",
    "\t\tfmt.Printf(\"error unmarshalling request body: %v\\n\", err.Error())\n",
    "\t\tw.WriteHeader(http.StatusBadRequest)\n",
    "\t\tw.Write([]byte(err.Error()))\n",
    "\t\treturn\t\n",
    "\t}\n",
    "\n",
    "\tresponse, err := HandleRequest(r.Context(), &event)\n",
    "\tif err != nil {\n",
    "\t\tfmt.Printf(\"error handling request: %v\\n\", err.Error())\n",
    "\t\tw.WriteHeader(http.StatusInternalServerError)\n",
    "\t\tw.Write([]byte(err.Error()))\n",
    "\t\treturn\t\n",
    "\t}\n",
    "\t\n",
    "\tresponseBytes, err := json.Marshal(response)\n",
    "\tif err != nil {\n",
    "\t\tfmt.Printf(\"error marshalling response: %v\\n\", err.Error())\n",
    "\t\tw.WriteHeader(http.StatusInternalServerError)\n",
    "\t\tw.Write([]byte(err.Error()))\n",
    "\t\treturn\t\n",
    "\t}\n",
    "\t\n",
    "\tw.WriteHeader(http.StatusOK)\n",
    "\tw.Write(responseBytes)\n",
    "}\n",
    "\n",
    "func main() {\n",
    "    listenAddr := \":8080\"\n",
    "    if val, ok := os.LookupEnv(\"FUNCTIONS_CUSTOMHANDLER_PORT\"); ok {\n",
    "        listenAddr = \":\" + val\n",
    "    }\n",
    "    http.HandleFunc(\"/api/HttpExample\", azureHandler)\n",
    "    http.ListenAndServe(listenAddr, nil)\n",
    "}\n",
    "```\n",
    "\n",
    "Step 2. Add these required imports\n",
    "\n",
    "```\n",
    "import (\n",
    "\t\"encoding/json\"\n",
    "\t\"io\"\n",
    "\t\"net/http\"\n",
    "\t\"os\"\n",
    ")\n",
    "```\n",
    "\n",
    "Step 3. Remove this lambda import\n",
    "\n",
    "```\n",
    "import (\n",
    "\t\"context\"\n",
    "\t\"fmt\"\n",
    "\n",
    "```\n",
    "\n",
    "You always return only code you never give explanations.\n",
    "If you don't know the answer return the original code with the following comment\n",
    "\n",
    "```\n",
    "// No code could be converted, please check the class\n",
    "```\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d55cb5e",
   "metadata": {},
   "source": [
    "### Using an example selector\n",
    "\n",
    "We will reuse the example set and the formatter from the previous section. However, instead of feeding the examples directly into the `FewShotPromptTemplate` object, we will feed them into an `ExampleSelector` object.\n",
    "\n",
    "In this tutorial, we will use the `SemanticSimilarityExampleSelector` class. This class selects few-shot examples based on their similarity to the input. It uses an embedding model to compute the similarity between the input and the few-shot examples, as well as a vector store to perform the nearest neighbor search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ec774f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_vectorize = [\" \".join(example.values()) for example in examples]\n",
    "vectorstore = Chroma.from_texts(to_vectorize, embeddings, metadatas=examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "105eb45c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of requested results 2 is greater than number of elements in index 1, updating n_results = 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'input': '\\npackage main\\n\\nimport (\\n\\t\"context\"\\n\\t\"fmt\"\\n\\t\"github.com/aws/aws-lambda-go/lambda\"\\n)\\n\\ntype MyEvent struct {\\n\\tName string `json:\"name\"`\\n}\\n\\ntype MyResponse struct {\\n\\tMessage string `json:\"message\"`\\n}\\n\\nfunc HandleRequest(ctx context.Context, event *MyEvent) (*MyResponse, error) {\\n\\tif event == nil {\\n\\t\\treturn nil, fmt.Errorf(\"received nil event\")\\n\\t}\\n\\tmessage := fmt.Sprintf(\"Hello %s!\", event.Name)\\n\\treturn &MyResponse{Message: message}, nil\\n}\\n\\nfunc main() {\\n\\tlambda.Start(HandleRequest)\\n}\\n\\n        ',\n",
       "  'output': '\\npackage main\\n\\nimport (\\n\\t\"fmt\"\\n\\t\"log\"\\n\\t\"net/http\"\\n\\t\"os\"\\n\\n\\t\"github.com/gin-gonic/gin\"\\n)\\n\\nconst (\\n\\tEnvVarAzureFunctionPort string = \"FUNCTIONS_PORT\"\\n)\\n\\ntype MyEvent struct {\\n\\tName string `json:\"name\"`\\n}\\n\\ntype MyResponse struct {\\n\\tMessage string `json:\"message\"`\\n}\\n\\nfunc HandleRequest(ctx *gin.Context) {\\n\\tif ctx.Request.Body == nil {\\n        errorMsg := \"received nil event\"    \\n\\t\\tfmt.Println(errorMsg)\\n\\t\\tctx.JSON(http.StatusBadRequest, gin.H{\"error\": errorMsg})\\n\\t\\treturn\\n\\t}\\n\\n\\tvar event MyEvent\\n\\terr := ctx.Bind(&event)\\n\\tif err != nil {\\n\\t\\tfmt.Printf(\"error on reading request body: %v\\n\", err.Error())\\n\\t\\tctx.JSON(http.StatusBadRequest, gin.H{\"error\": err.Error()})\\n\\t\\treturn\\n\\t}\\n\\tmessage := fmt.Sprintf(\"Hello %s!\", event.Name)\\n    ctx.JSON(http.StatusOK, &MyResponse{Message: message})\\n}\\n\\n\\nfunc main() {\\n r := gin.Default()\\n r.Handle(http.MethodPost, \"/HandleRequest\", HandleRequest)\\n\\n port, _ := os.LookupEnv(EnvVarAzureFunctionPort)\\n host := fmt.Sprintf(\"0.0.0.0:%s\", port)\\n fmt.Println(\"Go server Listening...on port: \", port)\\n log.Panic(r.Run(host))\\n}\\n\\n        '}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_selector = SemanticSimilarityExampleSelector(\n",
    "    vectorstore=vectorstore,\n",
    "    k=2,\n",
    ")\n",
    "\n",
    "# The prompt template will load examples by passing the input do the `select_examples` method\n",
    "example_selector.select_examples({\"input\": input})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c5d78d",
   "metadata": {},
   "source": [
    "### Create a formatter for the few-shot examples\n",
    "Configure a formatter that will format the few-shot examples into a string. This formatter should be a `FewShotChatMessagePromptTemplate` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b1656af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of requested results 2 is greater than number of elements in index 1, updating n_results = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: \n",
      "package main\n",
      "\n",
      "import (\n",
      "\t\"context\"\n",
      "\t\"fmt\"\n",
      "\t\"github.com/aws/aws-lambda-go/lambda\"\n",
      ")\n",
      "\n",
      "type MyEvent struct {\n",
      "\tName string `json:\"name\"`\n",
      "}\n",
      "\n",
      "type MyResponse struct {\n",
      "\tMessage string `json:\"message\"`\n",
      "}\n",
      "\n",
      "func HandleRequest(ctx context.Context, event *MyEvent) (*MyResponse, error) {\n",
      "\tif event == nil {\n",
      "\t\treturn nil, fmt.Errorf(\"received nil event\")\n",
      "\t}\n",
      "\tmessage := fmt.Sprintf(\"Hello %s!\", event.Name)\n",
      "\treturn &MyResponse{Message: message}, nil\n",
      "}\n",
      "\n",
      "func main() {\n",
      "\tlambda.Start(HandleRequest)\n",
      "}\n",
      "\n",
      "        \n",
      "AI: \n",
      "package main\n",
      "\n",
      "import (\n",
      "\t\"fmt\"\n",
      "\t\"log\"\n",
      "\t\"net/http\"\n",
      "\t\"os\"\n",
      "\n",
      "\t\"github.com/gin-gonic/gin\"\n",
      ")\n",
      "\n",
      "const (\n",
      "\tEnvVarAzureFunctionPort string = \"FUNCTIONS_PORT\"\n",
      ")\n",
      "\n",
      "type MyEvent struct {\n",
      "\tName string `json:\"name\"`\n",
      "}\n",
      "\n",
      "type MyResponse struct {\n",
      "\tMessage string `json:\"message\"`\n",
      "}\n",
      "\n",
      "func HandleRequest(ctx *gin.Context) {\n",
      "\tif ctx.Request.Body == nil {\n",
      "        errorMsg := \"received nil event\"    \n",
      "\t\tfmt.Println(errorMsg)\n",
      "\t\tctx.JSON(http.StatusBadRequest, gin.H{\"error\": errorMsg})\n",
      "\t\treturn\n",
      "\t}\n",
      "\n",
      "\tvar event MyEvent\n",
      "\terr := ctx.Bind(&event)\n",
      "\tif err != nil {\n",
      "\t\tfmt.Printf(\"error on reading request body: %v\n",
      "\", err.Error())\n",
      "\t\tctx.JSON(http.StatusBadRequest, gin.H{\"error\": err.Error()})\n",
      "\t\treturn\n",
      "\t}\n",
      "\tmessage := fmt.Sprintf(\"Hello %s!\", event.Name)\n",
      "    ctx.JSON(http.StatusOK, &MyResponse{Message: message})\n",
      "}\n",
      "\n",
      "\n",
      "func main() {\n",
      " r := gin.Default()\n",
      " r.Handle(http.MethodPost, \"/HandleRequest\", HandleRequest)\n",
      "\n",
      " port, _ := os.LookupEnv(EnvVarAzureFunctionPort)\n",
      " host := fmt.Sprintf(\"0.0.0.0:%s\", port)\n",
      " fmt.Println(\"Go server Listening...on port: \", port)\n",
      " log.Panic(r.Run(host))\n",
      "}\n",
      "\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "# Define the few-shot prompt.\n",
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    # The input variables select the values to pass to the example_selector\n",
    "    input_variables=[\"input\"],\n",
    "    example_selector=example_selector,\n",
    "    # Define how each example will be formatted.\n",
    "    # In this case, each example will become 2 messages:\n",
    "    # 1 human, and 1 AI\n",
    "    example_prompt=ChatPromptTemplate.from_messages(\n",
    "        [(\"human\", \"{input}\"), (\"ai\", \"{output}\")]\n",
    "    ),\n",
    ")\n",
    "\n",
    "print(few_shot_prompt.format(input=input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bcc77401",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'\\n\\tlambda'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 9\u001b[0m\n\u001b[0;32m      1\u001b[0m final_prompt \u001b[38;5;241m=\u001b[39m ChatPromptTemplate\u001b[38;5;241m.\u001b[39mfrom_messages(\n\u001b[0;32m      2\u001b[0m     [\n\u001b[0;32m      3\u001b[0m         (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msystem\u001b[39m\u001b[38;5;124m\"\u001b[39m, system_input),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      6\u001b[0m     ]\n\u001b[0;32m      7\u001b[0m )\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mfinal_prompt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mc:\\Workspace\\Americanas\\lambda-azfunction-converter-poc\\.conda\\Lib\\site-packages\\langchain_core\\prompts\\chat.py:586\u001b[0m, in \u001b[0;36mChatPromptTemplate.format\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    576\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mformat\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[0;32m    577\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Format the chat template into a string.\u001b[39;00m\n\u001b[0;32m    578\u001b[0m \n\u001b[0;32m    579\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    584\u001b[0m \u001b[38;5;124;03m        formatted string\u001b[39;00m\n\u001b[0;32m    585\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 586\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat_prompt\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto_string()\n",
      "File \u001b[1;32mc:\\Workspace\\Americanas\\lambda-azfunction-converter-poc\\.conda\\Lib\\site-packages\\langchain_core\\prompts\\chat.py:357\u001b[0m, in \u001b[0;36mBaseChatPromptTemplate.format_prompt\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mformat_prompt\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m PromptValue:\n\u001b[0;32m    349\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    350\u001b[0m \u001b[38;5;124;03m    Format prompt. Should return a PromptValue.\u001b[39;00m\n\u001b[0;32m    351\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    355\u001b[0m \u001b[38;5;124;03m        PromptValue.\u001b[39;00m\n\u001b[0;32m    356\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 357\u001b[0m     messages \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat_messages\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    358\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ChatPromptValue(messages\u001b[38;5;241m=\u001b[39mmessages)\n",
      "File \u001b[1;32mc:\\Workspace\\Americanas\\lambda-azfunction-converter-poc\\.conda\\Lib\\site-packages\\langchain_core\\prompts\\chat.py:611\u001b[0m, in \u001b[0;36mChatPromptTemplate.format_messages\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    603\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[0;32m    604\u001b[0m     message_template, (BaseMessagePromptTemplate, BaseChatPromptTemplate)\n\u001b[0;32m    605\u001b[0m ):\n\u001b[0;32m    606\u001b[0m     rel_params \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    607\u001b[0m         k: v\n\u001b[0;32m    608\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m    609\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m message_template\u001b[38;5;241m.\u001b[39minput_variables\n\u001b[0;32m    610\u001b[0m     }\n\u001b[1;32m--> 611\u001b[0m     message \u001b[38;5;241m=\u001b[39m \u001b[43mmessage_template\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat_messages\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrel_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    612\u001b[0m     result\u001b[38;5;241m.\u001b[39mextend(message)\n\u001b[0;32m    613\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Workspace\\Americanas\\lambda-azfunction-converter-poc\\.conda\\Lib\\site-packages\\langchain_core\\prompts\\chat.py:220\u001b[0m, in \u001b[0;36mBaseStringMessagePromptTemplate.format_messages\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    211\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mformat_messages\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[BaseMessage]:\n\u001b[0;32m    212\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Format messages from kwargs.\u001b[39;00m\n\u001b[0;32m    213\u001b[0m \n\u001b[0;32m    214\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    218\u001b[0m \u001b[38;5;124;03m        List of BaseMessages.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 220\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m]\n",
      "File \u001b[1;32mc:\\Workspace\\Americanas\\lambda-azfunction-converter-poc\\.conda\\Lib\\site-packages\\langchain_core\\prompts\\chat.py:320\u001b[0m, in \u001b[0;36mSystemMessagePromptTemplate.format\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    311\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mformat\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BaseMessage:\n\u001b[0;32m    312\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Format the prompt template.\u001b[39;00m\n\u001b[0;32m    313\u001b[0m \n\u001b[0;32m    314\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;124;03m        Formatted message.\u001b[39;00m\n\u001b[0;32m    319\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 320\u001b[0m     text \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprompt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    321\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SystemMessage(content\u001b[38;5;241m=\u001b[39mtext, additional_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madditional_kwargs)\n",
      "File \u001b[1;32mc:\\Workspace\\Americanas\\lambda-azfunction-converter-poc\\.conda\\Lib\\site-packages\\langchain_core\\prompts\\prompt.py:132\u001b[0m, in \u001b[0;36mPromptTemplate.format\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Format the prompt with the inputs.\u001b[39;00m\n\u001b[0;32m    118\u001b[0m \n\u001b[0;32m    119\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[38;5;124;03m        prompt.format(variable1=\"foo\")\u001b[39;00m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    131\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_merge_partial_and_user_variables(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 132\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDEFAULT_FORMATTER_MAPPING\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtemplate_format\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtemplate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Workspace\\Americanas\\lambda-azfunction-converter-poc\\.conda\\Lib\\string.py:190\u001b[0m, in \u001b[0;36mFormatter.format\u001b[1;34m(self, format_string, *args, **kwargs)\u001b[0m\n\u001b[0;32m    189\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mformat\u001b[39m(\u001b[38;5;28mself\u001b[39m, format_string, \u001b[38;5;241m/\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvformat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformat_string\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Workspace\\Americanas\\lambda-azfunction-converter-poc\\.conda\\Lib\\site-packages\\langchain_core\\utils\\formatting.py:29\u001b[0m, in \u001b[0;36mStrictFormatter.vformat\u001b[1;34m(self, format_string, args, kwargs)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     26\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo arguments should be provided, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     27\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meverything should be passed as keyword arguments.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     28\u001b[0m     )\n\u001b[1;32m---> 29\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvformat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformat_string\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Workspace\\Americanas\\lambda-azfunction-converter-poc\\.conda\\Lib\\string.py:194\u001b[0m, in \u001b[0;36mFormatter.vformat\u001b[1;34m(self, format_string, args, kwargs)\u001b[0m\n\u001b[0;32m    192\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvformat\u001b[39m(\u001b[38;5;28mself\u001b[39m, format_string, args, kwargs):\n\u001b[0;32m    193\u001b[0m     used_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n\u001b[1;32m--> 194\u001b[0m     result, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_vformat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformat_string\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mused_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    195\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_unused_args(used_args, args, kwargs)\n\u001b[0;32m    196\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Workspace\\Americanas\\lambda-azfunction-converter-poc\\.conda\\Lib\\string.py:234\u001b[0m, in \u001b[0;36mFormatter._vformat\u001b[1;34m(self, format_string, args, kwargs, used_args, recursion_depth, auto_arg_index)\u001b[0m\n\u001b[0;32m    230\u001b[0m     auto_arg_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;66;03m# given the field_name, find the object it references\u001b[39;00m\n\u001b[0;32m    233\u001b[0m \u001b[38;5;66;03m#  and the argument it came from\u001b[39;00m\n\u001b[1;32m--> 234\u001b[0m obj, arg_used \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_field\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfield_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    235\u001b[0m used_args\u001b[38;5;241m.\u001b[39madd(arg_used)\n\u001b[0;32m    237\u001b[0m \u001b[38;5;66;03m# do any conversion on the resulting object\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Workspace\\Americanas\\lambda-azfunction-converter-poc\\.conda\\Lib\\string.py:299\u001b[0m, in \u001b[0;36mFormatter.get_field\u001b[1;34m(self, field_name, args, kwargs)\u001b[0m\n\u001b[0;32m    296\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_field\u001b[39m(\u001b[38;5;28mself\u001b[39m, field_name, args, kwargs):\n\u001b[0;32m    297\u001b[0m     first, rest \u001b[38;5;241m=\u001b[39m _string\u001b[38;5;241m.\u001b[39mformatter_field_name_split(field_name)\n\u001b[1;32m--> 299\u001b[0m     obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfirst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    301\u001b[0m     \u001b[38;5;66;03m# loop through the rest of the field_name, doing\u001b[39;00m\n\u001b[0;32m    302\u001b[0m     \u001b[38;5;66;03m#  getattr or getitem as needed\u001b[39;00m\n\u001b[0;32m    303\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m is_attr, i \u001b[38;5;129;01min\u001b[39;00m rest:\n",
      "File \u001b[1;32mc:\\Workspace\\Americanas\\lambda-azfunction-converter-poc\\.conda\\Lib\\string.py:256\u001b[0m, in \u001b[0;36mFormatter.get_value\u001b[1;34m(self, key, args, kwargs)\u001b[0m\n\u001b[0;32m    254\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m args[key]\n\u001b[0;32m    255\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 256\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mkwargs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[1;31mKeyError\u001b[0m: '\\n\\tlambda'"
     ]
    }
   ],
   "source": [
    "final_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_input),\n",
    "        few_shot_prompt,\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(final_prompt.format(input=input))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b66abf00",
   "metadata": {},
   "source": [
    "### Use with an LLM\n",
    "Now, you can connect your model to the few-shot prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6fb91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation = ConversationChain(llm=llm)\n",
    "\n",
    "result = conversation.run(final_prompt.format_messages(input=input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4201fad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97621902",
   "metadata": {},
   "source": [
    "### Check if compiles \n",
    "\n",
    "The idea would be to compile the classes and if it doesn't compile tell the LLM the issue and retry.\n",
    "\n",
    "The result doesn't seem to compile let's ask the LLM again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7522456",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation.run(\"the code doesn't compile\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efefb22c",
   "metadata": {},
   "source": [
    "### Let's try with format instructions\n",
    "\n",
    "It's possible to tell our LLM how we expect to get our response back using output parsers, let's try it out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31165df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a2f732a0",
   "metadata": {},
   "source": [
    "### Testing more inputs\n",
    "\n",
    "Try again using new inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0822d811",
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_code_1 = '''\n",
    "package main\n",
    "\n",
    "import (\n",
    "\t\"context\"\n",
    "\t\"encoding/json\"\n",
    "\t\"github.com/aws/aws-lambda-go/events\"\n",
    "\truntime \"github.com/aws/aws-lambda-go/lambda\"\n",
    "\t\"github.com/aws/aws-lambda-go/lambdacontext\"\n",
    "\t\"github.com/aws/aws-sdk-go/aws/session\"\n",
    "\t\"github.com/aws/aws-sdk-go/service/lambda\"\n",
    "\t\"log\"\n",
    "\t\"os\"\n",
    ")\n",
    "\n",
    "var client = lambda.New(session.New())\n",
    "\n",
    "func callLambda() (string, error) {\n",
    "\tinput := &lambda.GetAccountSettingsInput{}\n",
    "\treq, resp := client.GetAccountSettingsRequest(input)\n",
    "\terr := req.Send()\n",
    "\toutput, _ := json.Marshal(resp.AccountUsage)\n",
    "\treturn string(output), err\n",
    "}\n",
    "\n",
    "func handleRequest(ctx context.Context, event events.SQSEvent) (string, error) {\n",
    "\t// event\n",
    "\teventJson, _ := json.MarshalIndent(event, \"\", \"  \")\n",
    "\tlog.Printf(\"EVENT: %s\", eventJson)\n",
    "\t// environment variables\n",
    "\tlog.Printf(\"REGION: %s\", os.Getenv(\"AWS_REGION\"))\n",
    "\tlog.Println(\"ALL ENV VARS:\")\n",
    "\tfor _, element := range os.Environ() {\n",
    "\t\tlog.Println(element)\n",
    "\t}\n",
    "\t// request context\n",
    "\tlc, _ := lambdacontext.FromContext(ctx)\n",
    "\tlog.Printf(\"REQUEST ID: %s\", lc.AwsRequestID)\n",
    "\t// global variable\n",
    "\tlog.Printf(\"FUNCTION NAME: %s\", lambdacontext.FunctionName)\n",
    "\t// context method\n",
    "\tdeadline, _ := ctx.Deadline()\n",
    "\tlog.Printf(\"DEADLINE: %s\", deadline)\n",
    "\t// AWS SDK call\n",
    "\tusage, err := callLambda()\n",
    "\tif err != nil {\n",
    "\t\treturn \"ERROR\", err\n",
    "\t}\n",
    "\treturn usage, nil\n",
    "}\n",
    "\n",
    "func main() {\n",
    "\truntime.Start(handleRequest)\n",
    "}\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2187c66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation = ConversationChain(llm=llm)\n",
    "\n",
    "result = conversation.run(final_prompt.format_messages(input=lambda_code_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1315319",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
